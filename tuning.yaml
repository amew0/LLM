meta-llama/Meta-Llama-3-8B-Instruct: 
  prompt: |
    <|start_header_id|>system<|end_header_id|>
    {}<|eot_id|>
    <|start_header_id|>user<|end_header_id|>
    Question: {}<|eot_id|>
    <|start_header_id|>assistant<|end_header_id|>
  response: |
    {}<|eot_id|>
  peft_args: 
    r: 4
    lora_alpha: 16
    target_modules: ["q_proj", "o_proj", "k_proj", "v_proj", "gate_proj"]
    lora_dropout: 0.05
    bias: none
    task_type: CAUSAL_LM
  training_args: 
    warmup_ratio: 0.1
    num_train_epochs: 3
    learning_rate: 3e-4
    fp16: False
    logging_steps: 10
    optim: adamw_torch
    group_by_length: False
    dataloader_drop_last: False
    save_steps: 400
    save_total_limit: 3

EleutherAI/pythia-70m-deduped:
  prompt: |
    ### System:
    {}<|endoftext|>
    ### User:
    {}<|endoftext|>
    ### Assistant:
  response: |
    {}<|endoftext|>