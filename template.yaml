# legend
# name is the hf name of the model
# prompt is the typical text-generation prompt used by the model
# evaluator_prompt is the formatted prompt to use for laaj (llm-as-a-judge)
# evaluator_prompt should place the expected placeholder first and then the generated

meta-llama/Meta-Llama-3-8B-Instruct: 
  candidate_prompt: <|start_header_id|>system<|end_header_id|> {}<|eot_id|><|start_header_id|>user<|end_header_id|> {}<|eot_id|><|start_header_id|>assistant<|end_header_id|>
  candidate_generation_config: 
    max_new_tokens: 256
    do_sample: True
    temperature: 0.6
    top_p: 0.9
  
  # evaluator_prompt: |
  #   <|start_header_id|>system<|end_header_id|>
  #   You are going to act as an LLM evaluator to rate the answer of the LLM generated medical chatbot on factualness (i.e how contextually the generated output followed the expected reply). Penalize it appropriately for any hallucination/loss of context, refraining to answer (saying 'As an AI Language Model', 'I am not a doctor, but' ...), or trailing repetition. YOUR RESPONSE IS NOTHING ELSE BUT A FLOAT FROM 0.0 - 5.0 (with format x.x). Where 0.0 indicates the context of the generated response is very far from the expected one. And 5.0 represents otherwise. AGAIN IF YOUR GENERATED ANYTHING ELSE BUT A FLOAT YOU'RE GOING TO CRUSH MY SYSTEM!!<|eot_id|>
  #   <|start_header_id|>user<|end_header_id|>
  #   ### Expected: {}
  #   ### Generated: {}<|eot_id|>
  #   <|start_header_id|>assistant<|end_header_id|>
  evaluator_prompt: |
    <|start_header_id|>system<|end_header_id|>
    [YOUR OUTPUT IS NOTHING ELSE BUT A SCORE FROM 0.0 - 5.0] You will be given one response of a medical chatbot and the expected response.\n\nYour task is to rate the answer of the medical chatbot on one metric.\n\nPlease make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as needed.\n\nEvaluation Criteria:\n\nMedical Accuracy (0.0 - 5.0) evaluates the precision and reliability of responses in diagnosing and treating medical conditions. Key criteria include:\n\n1) Diagnostic Precision: Responses should accurately interpret symptoms and provide correct diagnostic information based on current medical knowledge.\n\n2) Treatment Consistency: Information should align with recommended treatment protocols supported by robust evidence from clinical trials and expert consensus.\n\n3) Clinical Relevance: Responses should consider variations in disease presentation, patient demographics, and comorbidities to ensure relevance to clinical practice.\n\n4) Clarity and Completeness: All medical explanations and recommendations should be clear, comprehensive, and free from ambiguity or oversimplification.\n\n5) Consistency with Medical Standards: Responses should align with established medical standards and practices, avoiding contradictory or speculative claims.\n\n6) Updated Content: Regular updates should reflect advancements in medical research and changes in treatment standards to maintain current relevance.\n\n7) Safety and Ethical Guidelines: Recommendations for medical interventions should prioritize patient safety and adhere to ethical guidelines and legal standards.\n\n\nEvaluation Steps:\n\n1) Read the expected medical accuracy criteria carefully and understand the key components: diagnostic precision, treatment consistency, clinical relevance, clarity and completeness, consistency with medical standards, updated content, and adherence to safety and ethical guidelines.\n\n2) Evaluate the medical chatbot response by comparing it against the expected criteria. Determine if the response accurately interprets symptoms and provides correct diagnostic \ninformation, adheres to recommended treatment protocols with evidence-based support, considers variations in disease presentation and patient demographics, and maintains clarity and completeness in explanations.\n\n3) Assign a score for Medical Chatbot response on a scale of 0.0 to 5.0 based on the evaluation criteria (Medical Accuracy)\n\nScoring:\nAssign a score for Medical Accuracy on a scale of 0.0 to 5.0 based on the evaluation:\n\n5.0: The response consistently demonstrates precise diagnoses and evidence-based treatment recommendations, and meets all criteria with exceptional accuracy and reliability.\n\n4.0-4.9: Minor inaccuracies or occasional gaps may be present, but overall, the response aligns well with the majority of the criteria.\n\n3.0-3.9: Some inconsistencies or significant gaps in information may require clarification or improvement to enhance accuracy and reliability.\n\n2.0-2.9: Major inaccuracies or substantial gaps significantly impact reliability and may require substantial revision.\n\n0.0-1.9: The response is consistently inaccurate or lacks essential information, failing to meet the expected criteria for reliability and accuracy.\n\n\nExample:\n\nExpected Medical Chatbot Response: [Chatbot response] \n\nGenerated Medical Chatbot Response: [Chatbot response]\n\nEvaluation Form  only add the final score without any explanation or any additional words :\n\n- Medical Accuracy: \n
    <|start_header_id|>user<|end_header_id|>
    Expected Medical Chatbot Response: {}
    Generated Medical Chatbot Response: {}
    - Medical Accuracy: x.x<|eot_id|>
    <|start_header_id|>assistant<|end_header_id|>
  evaluator_generation_config: 
    max_new_tokens: 256
    do_sample: True
    temperature: 0.6
    top_p: 0.9

microsoft/Phi-3-mini-4k-instruct:
  candidate_prompt: |
    <|system|>
    {}<|end|>
    <|user|>
    {}<|end|>
    <|assistant|>
  evaluator_prompt: 

Qwen/Qwen2-7B-Instruct:
  evaluator_prompt: |
    <|im_start|>system
    You are going to act as an LLM evaluator to rate the answer of the LLM generated medical chatbot on factualness (i.e how contextually the generated output followed the expected reply). Penalize it appropriately for any hallucination/loss of context, refraining to answer (saying 'As an AI Language Model', 'I am not a doctor, but' ...), or trailing repetition. YOUR RESPONSE IS NOTHING ELSE BUT A FLOAT FROM 0.0 - 5.0 (with format x.x). Where 0.0 indicates the context of the generated response is very far from the expected one. And 5.0 represents otherwise. AGAIN IF YOUR GENERATED ANYTHING ELSE BUT A FLOAT YOU'RE GOING TO CRUSH MY SYSTEM!!<|im_end|>
    <|im_start|>user
    ### Expected: {}
    ### Generated: {}<|eot_id|><|im_end|>
    <|im_start|>assistant
    
 